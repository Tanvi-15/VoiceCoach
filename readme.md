# ğŸ¤ VoiceCoach â€” Automated Speech Feedback with Whisper + Praat + LLMs

VoiceCoach is a **speech analysis and coaching tool** that takes `.wav` / `.m4a` recordings and provides **quantitative metrics** (clarity, pacing, cadence, engagement) plus **personalized feedback**.  
It combines **ASR (Whisper)**, **prosody analysis (Praat + Librosa)**, custom **pause detection**, and an **LLM feedback engine (Mistral-7B via Ollama)**.  
A **Streamlit dashboard** makes results interactive, with transcripts, rubric scores, speech/pause timelines, and JSON export.

---

## âœ¨ Features

- ğŸ”Š **Automatic Speech Recognition** with [faster-whisper](https://github.com/guillaumekln/faster-whisper)  
- ğŸ¶ **Prosody extraction** via [Praat (Parselmouth)](https://parselmouth.readthedocs.io) and [Librosa](https://librosa.org)  
  - Pitch (F0), intensity, jitter, shimmer, harmonic-to-noise ratio  
  - RMS energy, tempo, spectral centroid  
- â¸ï¸ **Pause detection** using Whisper word timestamps  
  - Buckets pauses into *short (0.12â€“0.25s)*, *good (0.25â€“0.60s)*, *medium (0.60â€“1.0s)*, *long (â‰¥1.0s)*  
  - Computes pause ratio, good vs bad pause ratios, rates per minute  
- ğŸ“Š **Metrics and Rubric Scoring**  
  - Clarity, Confidence, Tone, Pacing, Engagement, Cadence, Flow (1â€“5 scale)  
- ğŸ¤– **LLM-powered feedback** with [Ollama](https://ollama.ai) + [Mistral 7B](https://mistral.ai) (local)  
- ğŸŒ **Streamlit Frontend**  
  - Upload audio, view transcript, summary metrics, rubric table  
  - Pause quality breakdown and timeline visualization  
  - JSON download for results  

---

## ğŸ› ï¸ Tech Stack

- **Python 3.10+**
- [Whisper (faster-whisper / CTranslate2)](https://github.com/guillaumekln/faster-whisper)  
- [Praat (Parselmouth)](https://parselmouth.readthedocs.io)  
- [Librosa](https://librosa.org)  
- [Pyphen](https://github.com/Kozea/pyphen) â€” syllable counting  
- [Streamlit](https://streamlit.io) â€” frontend dashboard  
- [Altair](https://altair-viz.github.io) â€” timeline visualization  
- [Ollama](https://ollama.ai) â€” local LLM runner  
- [Mistral 7B](https://mistral.ai) â€” feedback model  

---

## ğŸ“‚ Project Structure

```
VoiceCoach/
   â”œâ”€â”€ app.py                    # Streamlit web dashboard
   â”œâ”€â”€ main.py                   # Command-line interface
   â”œâ”€â”€ utils_audio.py            # Audio processing utilities (FFmpeg â†’ WAV)
   â”œâ”€â”€ asr_whisper.py            # Whisper ASR integration
   â”œâ”€â”€ prosody_praat.py          # Prosody analysis via Praat
   â”œâ”€â”€ prosody_librosa.py        # Prosody analysis via Librosa
   â”œâ”€â”€ vad_from_asr.py           # Voice Activity & pause detection
   â”œâ”€â”€ metrics.py                # Derived metrics (WPM, clarity, etc.)
   â”œâ”€â”€ rubric.py                 # Rubric scoring system (1-5 scale)
   â”œâ”€â”€ coach_ollama.py           # LLM feedback engine (Ollama + Mistral)
   â”œâ”€â”€ requirements.txt          # Python dependencies
   â””â”€â”€ demo_assets/              # Sample audio files for testing
       â”œâ”€â”€ harvard.wav
       â”œâ”€â”€ test2.m4a
       â””â”€â”€ vani.m4a

```

---

## ğŸš€ Usage

### 1. Install dependencies
```bash
pip install -r requirements.txt
```
Make sure [FFmpeg](https://www.ffmpeg.org/download.html) is installed (for audio conversion).

```

python main.py --audio demo_assets/harvard.wav --whisper base.en --ollama-model mistral:7b
```
Outputs a JSON report with all metrics, rubric scores, and feedback.

```
streamlit run app.py
```
Runs streamlit UI

- Upload .wav or .m4a audio
- View transcript, summary metrics, rubric scores
- Inspect pause quality and timeline
- Read coaching feedback
- Download JSON results
